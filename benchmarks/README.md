# Benchmarks - Pruebas de Rendimiento y Evaluaci√≥n

Este directorio contiene las pruebas de rendimiento y evaluaci√≥n del chatbot UniPet, incluyendo an√°lisis de tiempos de respuesta y evaluaciones de calidad mediante el m√©todo **LLM-as-a-Judge**.

---

## üìã Requisitos Previos

- **Python**: 3.11 o superior
- **pip**: Gestor de paquetes de Python
- **Jupyter Notebook** o **VS Code** con extensi√≥n de Jupyter

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### 1. Navegar a la Carpeta de Benchmarks

```bash
cd benchmarks
```

### 2. Crear Entorno Virtual

```bash
python -m venv env
```

### 3. Activar Entorno Virtual

**Windows (PowerShell):**
```bash
.\env\Scripts\Activate.ps1
```

**Windows (CMD):**
```bash
.\env\Scripts\activate.bat
```

**Linux/macOS:**
```bash
source env/bin/activate
```

### 4. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 5. Ejecutar los Notebooks

Abre los notebooks en VS Code o Jupyter:

```bash
jupyter notebook
```

---

## üìÅ Estructura del Proyecto

```text
benchmarks/
‚îú‚îÄ‚îÄ speed_test/                    # Pruebas de rendimiento
‚îÇ   ‚îú‚îÄ‚îÄ data/                      # Datos de prueba (.xlsx)
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/                 # An√°lisis de tiempos de respuesta
‚îÇ   ‚îî‚îÄ‚îÄ plots/                     # Gr√°ficas generadas
‚îÇ
‚îú‚îÄ‚îÄ test_just_as_a_judge/          # Evaluaci√≥n LLM-as-a-Judge
‚îÇ   ‚îú‚îÄ‚îÄ data/                      # Resultados de evaluaciones (.xlsx)
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/                 # An√°lisis de fundamentaci√≥n y relevancia
‚îÇ   ‚îî‚îÄ‚îÄ plots/                     # Gr√°ficas de m√©tricas
‚îÇ
‚îú‚îÄ‚îÄ emotion_model_comparison/      # Comparaci√≥n de modelos de emociones
‚îÇ   ‚îú‚îÄ‚îÄ data/                      # Datasets de emociones (.csv)
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/                 # An√°lisis comparativo de modelos
‚îÇ   ‚îî‚îÄ‚îÄ plots/                     # Visualizaciones comparativas
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md
```

> üìä **Nota:** Los archivos Excel (`.xlsx`) y CSV contienen los datos crudos de las pruebas realizadas, permitiendo reproducir los an√°lisis.

---

## üß™ Descripci√≥n de las Pruebas

### ‚ö° Prueba de Rendimiento (`speed_test/`)

Evaluaci√≥n del tiempo de respuesta del chatbot utilizando **20 preguntas independientes** enviadas secuencialmente v√≠a HTTP.

**M√©tricas calculadas:**
- Tiempo promedio de respuesta
- Tiempo m√≠nimo y m√°ximo
- Distribuci√≥n de tiempos

**Resultado destacado:** El tiempo promedio de respuesta fue de **4.57 segundos**, dentro del rango aceptable seg√∫n los estudios de Robert B. Miller sobre interacci√≥n humano-computadora, donde usuarios toleran hasta 4.6 segundos en tareas complejas.

---

### üßë‚Äç‚öñÔ∏è LLM-as-a-Judge (`test_just_as_a_judge/`)

M√©todo de evaluaci√≥n donde un modelo de lenguaje avanzado (**GPT-4o**) act√∫a como juez para evaluar las respuestas del chatbot.

#### Fundamentaci√≥n (Grounding)

Verifica que las respuestas est√©n respaldadas por el contexto RAG proporcionado.

| M√©trica | Valor |
|---------|-------|
| Escala | 0 - 5 |
| Promedio | 2.55 |

> **Nota:** Las puntuaciones bajas corresponden a interacciones con emociones positivas, donde el RAG no es necesario ya que est√° dise√±ado para situaciones de deterioro emocional.

#### Relevancia (Relevance)

Eval√∫a qu√© tan alineada est√° la respuesta con la intenci√≥n del usuario y la emoci√≥n detectada.

| M√©trica | Valor |
|---------|-------|
| Escala | 0 - 5 |
| Promedio | **4.8** |

> El alto puntaje de relevancia confirma que el chatbot responde apropiadamente seg√∫n el contexto emocional, priorizando empat√≠a en emociones positivas sobre el uso del RAG.

---

### üé≠ Comparaci√≥n de Modelos de Emociones (`emotion_model_comparison/`)

Evaluaci√≥n comparativa de modelos pre-entrenados para el reconocimiento de emociones en texto. La selecci√≥n del modelo es cr√≠tica para:

- Detectar el estado an√≠mico del estudiante en tiempo real
- Adaptar respuestas emp√°ticas al contexto emocional
- Identificar momentos que requieren escalamiento a apoyo profesional

#### Modelos Evaluados

| Modelo | Arquitectura | F1 Score | Idioma |
|--------|--------------|----------|--------|
| **PySentimiento** | RoBERTuito (RoBERTa) | 68.9% | Espa√±ol, Ingl√©s, Italiano, Portugu√©s |
| **monologg/bert-base-cased-goemotions-ekman** | BERT | 62.38% | Ingl√©s |
| **Daveni/twitter-xlm-roberta-emotion-es** | XLM-RoBERTa | **71.70%** | Espa√±ol |

#### Descripci√≥n de Modelos

**PySentimiento**
- Biblioteca Python multiling√ºe de c√≥digo abierto
- Construida sobre HuggingFace Transformers
- Utiliza RoBERTuito para espa√±ol (basado en RoBERTa)

**monologg/bert-base-cased-goemotions-ekman**
- Basado en BERT con taxonom√≠a de Paul Ekman
- Entrenado con GoEmotions (58,000 comentarios de Reddit)
- Clasifica 6 emociones b√°sicas + neutral

**Daveni/twitter-xlm-roberta-emotion-es**
- Arquitectura XLM-RoBERTa-base
- Entrenado en 198 millones de tweets
- üèÜ 1er lugar en EmoEvalEs@IberLEF 2021
- Clasifica: ira, disgusto, miedo, alegr√≠a, tristeza, sorpresa, otros

---

### üìä Ejemplo de Evaluaci√≥n

| Componente | Contenido |
|------------|-----------|
| **Entrada usuario** | "Saqu√© buena nota en la expo, vali√≥ la pena trasnochar." |
| **Respuesta chatbot** | "¬°Qu√© bien! Felicitaciones por esa buena nota... ¬øTienes alg√∫n plan para celebrar tu √©xito? üéâ‚ú®" |
| **Fundamentaci√≥n** | 0.5 (No requiere RAG para emociones positivas) |
| **Relevancia** | 5.0 (Respuesta emp√°tica y apropiada) |

---

## üìà Gr√°ficas Generadas

Las visualizaciones se encuentran en las carpetas `plots/` de cada prueba:

- `speed_test/plots/` - Distribuci√≥n de tiempos, estad√≠sticas
- `test_just_as_a_judge/plots/` - M√©tricas de fundamentaci√≥n y relevancia
- `emotion_model_comparison/plots/` - Comparaci√≥n de modelos de emociones
